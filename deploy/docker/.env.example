# Crawl4AI Environment Configuration
# Copy this file to .env in the PROJECT ROOT: cp deploy/docker/.env.example .env
# Then customize with your settings

# ──────────────────────────────────────────────────────────────────
# Port Configuration
# ──────────────────────────────────────────────────────────────────
# Host port mapping (container always runs on 11235 internally)
HOST_PORT=11235

# ──────────────────────────────────────────────────────────────────
# LLM Provider API Keys (Runtime Configuration)
# ──────────────────────────────────────────────────────────────────
# Add your API keys for the LLM providers you want to use
OPENAI_API_KEY=
DEEPSEEK_API_KEY=
ANTHROPIC_API_KEY=
GROQ_API_KEY=
TOGETHER_API_KEY=
MISTRAL_API_KEY=
GEMINI_API_TOKEN=

# Optional: Override the default LLM provider
# Examples: "openai/gpt-4.1-mini", "anthropic/claude-4-sonnet", "deepseek/chat"
# If not set, uses the provider specified in config.yml (default: openai/gpt-4o-mini)
# LLM_PROVIDER=anthropic/claude-3-opus

# ──────────────────────────────────────────────────────────────────
# Docker Image Selection (Optional)
# ──────────────────────────────────────────────────────────────────
# Use pre-built image from Docker Hub (recommended)
# IMAGE=unclecode/crawl4ai:latest
# TAG=latest

# ──────────────────────────────────────────────────────────────────
# Build Configuration (Only applies when building locally)
# ──────────────────────────────────────────────────────────────────

# INSTALL_TYPE: Feature set for the installation
#   - default: Basic installation (~2-3GB image)
#             Includes: JsonCssExtractionStrategy, JsonXPathExtractionStrategy,
#                      LLMExtractionStrategy (API-based, no local ML)
#             Best for: Standard web crawling, structured extraction, LLM-based extraction
#
#   - all: Full installation with ML dependencies (~6-8GB image)
#         Adds: PyTorch, transformers, sentence-transformers, scikit-learn, NLTK
#         Enables: CosineStrategy (semantic clustering), local transformer models
#         Best for: Advanced ML-based extraction, semantic content analysis
#
#   - torch: PyTorch + scikit-learn + NLTK (no transformers)
#   - transformer: Transformers + sentence-transformers (no PyTorch)
#
INSTALL_TYPE=default

# ENABLE_GPU: Enable NVIDIA CUDA support for GPU acceleration
#   - false: CPU-only (works on all platforms)
#   - true: Adds CUDA toolkit (AMD64/x86_64 only, requires NVIDIA GPU)
#
# Note: GPU support only available on AMD64 architecture
#       ARM64 (Apple Silicon) will skip GPU installation
#
ENABLE_GPU=false